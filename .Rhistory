"hc_mortgage_mean","hc_mortgage_median","hc_mortgage_stdev",
"hc_mortgage_sample","hc_mortgage_sample_weight",
"hc_mean","hc_median","hc_stdev","hc_samples","hc_sample_weight",
"rent_mean","rent_median","rent_stdev","rent_samples","rent_sample_weight",
"rent_gt_10","rent_gt_15","rent_gt_20","rent_gt_25","rent_gt_30",
"rent_gt_35","rent_gt_40","rent_gt_50","rent_universe_samples","rent_used_samples",
"family_income_mean","family_income_median","family_income_stdev","family_income_families",
"hi_mean","hi_median","hi_stdev","hi_samples","hi_sample_weight"
)
col_mapping <- c(
"family_mean" = "family_income_mean",
"family_median" = "family_income_median",
"family_stdev" = "family_income_stdev",
"family_samples" = "family_income_families",
"universe_samples" = "rent_universe_samples",
"used_samples" = "rent_used_samples",
"hc_mortgage_samples" = "hc_mortgage_sample",
"hc_mortgage_sample_weight" = "hc_mortgage_sample_weight"
)
names(df) <- ifelse(names(df) %in% names(col_mapping), col_mapping[names(df)], names(df))
df2 <- df[, intersect(names(df), columns)]
dim(df2)
object.size(df2)
str(df2)
df2 <- subset(df2, select = -c(BLOCKID, UID))
cat_cols <- c("state", "state_ab", "city", "place", "type", "primary")
df2[cat_cols] <- lapply(df2[cat_cols], as.factor)
library(stringr)
df2$city    <- str_to_title(df2$city)
df2$place   <- str_to_title(df2$place)
df2$type    <- str_to_title(df2$type)
df2$primary <- tolower(df2$primary)
colSums(is.na(df2))
num_cols <- sapply(df2, is.numeric)
df2[num_cols] <- lapply(df2[num_cols], function(x) {
x[is.na(x)] <- median(x, na.rm = TRUE)
return(x)
})
# Function to compute mode (most frequent value)
get_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
cat_cols <- c("state", "state_ab", "city", "place", "type", "primary")
df2[cat_cols] <- lapply(df2[cat_cols], function(x) {
mode_val <- get_mode(x[!is.na(x)])      # compute mode excluding NA
x[is.na(x)] <- mode_val                 # replace NA with mode
return(x)
})
colSums(is.na(df2))
# Remove Duplicate Rows
df2 <- unique(df2)
# Select numeric columns
num_cols <- sapply(df2, is.numeric)
num_data <- df2[, num_cols]
# Exclude ALand and AWater
num_data <- num_data[, !names(num_data) %in% c("ALand", "AWater")]
# Function to calculate number of outliers using IQR
count_outliers <- function(x) {
Q1 <- quantile(x, 0.25, na.rm = TRUE)
Q3 <- quantile(x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
sum(x < (Q1 - 1.5*IQR) | x > (Q3 + 1.5*IQR), na.rm = TRUE)
}
# Apply the function to all numeric columns
outlier_counts <- sapply(num_data, count_outliers)
# Convert to data.frame for better display
outlier_counts_df <- data.frame(
Variable = names(outlier_counts),
Num_Outliers = as.numeric(outlier_counts)
)
# Sort by number of outliers (descending)
outlier_counts_df <- outlier_counts_df[order(-outlier_counts_df$Num_Outliers), ]
# Display
outlier_counts_df
library(ggplot2)
# Select top 15 variables with most outliers
top15_outliers <- head(outlier_counts_df, 15)
# Create horizontal bar plot
ggplot(top15_outliers, aes(x = reorder(Variable, Num_Outliers), y = Num_Outliers)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Top 15 Numeric Variables by Number of Outliers",
x = "Variable",
y = "Number of Outliers") +
theme_minimal() +
coord_flip() +  # horizontal orientation
theme(
text = element_text(size = 12),       # larger text
axis.text.y = element_text(size = 10)
)
library(dplyr)
library(knitr)
num_cols <- sapply(df2, is.numeric)
num_data <- df2[, num_cols]
# Create summary table
num_summary <- data.frame(
Variable = names(num_data),
Min = sapply(num_data, min, na.rm = TRUE),
Q1 = sapply(num_data, quantile, 0.25, na.rm = TRUE),
Median = sapply(num_data, median, na.rm = TRUE),
Mean = sapply(num_data, mean, na.rm = TRUE),
Q3 = sapply(num_data, quantile, 0.75, na.rm = TRUE),
Max = sapply(num_data, max, na.rm = TRUE),
SD = sapply(num_data, sd, na.rm = TRUE),
IQR = sapply(num_data, IQR, na.rm = TRUE)
)
# Display nicely
kable(num_summary, caption = "Summary Statistics for Numeric Variables")
cat_cols <- sapply(df2, is.factor)
cat_data <- df2[, cat_cols]
# Create frequency table for each categorical variable
cat_summary <- lapply(names(cat_data), function(col){
temp <- as.data.frame(table(cat_data[[col]]))
colnames(temp) <- c(col, "Frequency")
temp$Percentage <- round(temp$Frequency / sum(temp$Frequency) * 100, 2)
temp
})
# Optional: display each table separately
for(i in 1:length(cat_summary)){
cat("\n###", names(cat_data)[i], "\n")
print(kable(cat_summary[[i]]))
}
library(ggplot2)
numeric_vars <- names(df2)[num_cols]
for(col in numeric_vars){
p <- ggplot(df2, aes_string(x = col)) +
geom_histogram(fill = "skyblue", color = "black", bins = 30) +
labs(title = paste("Histogram of", col), x = col, y = "Frequency") +
theme_minimal()
print(p)  # print the plot object
}
for(col in numeric_vars){
p <- ggplot(df2, aes_string(y=col)) +
geom_boxplot(fill="lightgreen", outlier.color="red") +
labs(title=paste("Boxplot of", col), y=col) +
theme_minimal()
print(p)
}
for(col in names(df2)[cat_cols]){
p <- ggplot(df2, aes_string(x=col)) +
geom_bar(fill="lightblue") +
labs(title=paste("Bar Plot of", col), x=col, y="Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle=45, hjust=1))
print(p)
}
ggplot(df2, aes(x=hi_mean, y=rent_mean)) +
geom_point(alpha=0.5, color="blue") +
labs(title="Rent Mean vs Household Income Mean", x="hi_mean", y="rent_mean") +
theme_minimal()
ggplot(df2, aes(x=pop, y=hi_mean)) +
geom_point(alpha=0.5, color="darkgreen") +
labs(title="Population vs Household Income Mean", x="Population", y="hi_mean") +
theme_minimal()
ggplot(df2, aes(x = debt)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "lightgreen", color = "black", alpha = 0.6) +
geom_density(color = "blue", size = 1) +
labs(title = "Left-Skewed Distribution of Debt",
x = "debt",
y = "Density") +
theme_minimal()
library(ggplot2)
ggplot(df2, aes(x = rent_mean)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black", alpha = 0.6) +
geom_density(color = "red", size = 1) +
labs(title = "Right-Skewed Distribution of Rent Mean",
x = "rent_mean",
y = "Density") +
theme_minimal()
numerics <- select_if(df2, is.numeric)
colnames(numerics)
subset.family <- numerics %>%
filter(!is.na(family_income_mean))
p_family <- ggplot(subset.family, aes(x = family_income_mean)) +
geom_histogram(aes(y = ..density..), bins = 40, fill = "#58ACFA", alpha = 0.6) +
geom_density(color = "black", size = 1) +  # smooth curve from actual data
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5)) +
labs(
title = "Distribution of Family Mean Income",
x = "Family Mean Income",
y = "Probability Density"
)
p_family
# Set layout: 3 rows, 1 column
par(mfrow = c(3, 1), mar = c(4, 4, 3, 1))
# Helper function for scatter plots
scatter_plot <- function(x, y, xlab, ylab, title) {
# Remove NA values
valid <- complete.cases(x, y)
x <- x[valid]
y <- y[valid]
# Scatter plot
plot(x, y,
pch = 16, col = "darkblue",
xlab = xlab, ylab = ylab,
main = title)
# Regression line
abline(lm(y ~ x), col = "red", lwd = 2)
}
# 1️⃣ Income vs Rent
scatter_plot(df$hi_mean,
df$rent_mean,
"Household Income (hi_mean)",
"Rent Mean",
"Income vs Rent")
# 2️⃣ Debt vs Income
scatter_plot(df$hi_mean,
df$debt,
"Household Income (hi_mean)",
"Debt",
"Debt vs Income")
# 3️⃣ Education vs Income
scatter_plot(df$hs_degree,
df$hi_mean,
"High School Degree Rate (hs_degree)",
"Household Income (hi_mean)",
"Education vs Income")
# Aggregate population by city
city_pop <- tapply(df2$pop, df2$city, sum, na.rm = TRUE)
# Sort and select top 10
top10 <- sort(city_pop, decreasing = TRUE)[1:10]
# Barplot
barplot(top10,
las = 3,
col = "steelblue",
main = "Top 10 Cities by Total Population",
ylab = "Population",
cex.names = 0.8)
# Compute median income per state
state_income <- tapply(df2$hi_mean, df2$state, median, na.rm = TRUE)
# Sort states by median income (highest first)
state_income_sorted <- sort(state_income, decreasing = TRUE)
# Select top 10 states
top10_states <- state_income_sorted[1:10]
# Barplot of Top 10 states
barplot(top10_states,
las = 3,
col = "lightgreen",
main = "Top 10 States by Median Household Income",
ylab = "Median Income",
cex.names = 0.9)
ggplot(df2, aes(x = hi_mean, y = rent_mean)) +
geom_point(alpha = 0.5, color="purple") +
geom_smooth(method="lm", se=FALSE, color="red") +
labs(title = "Rent Mean vs Household Income Mean",
x = "Household Income Mean",
y = "Rent Mean") +
theme_minimal()
library(dplyr)
top_cities <- df2 %>%
group_by(city) %>%
summarise(total_pop = sum(pop, na.rm = TRUE)) %>%
arrange(desc(total_pop)) %>%
slice_head(n = 10)
df_top <- df2 %>% filter(city %in% top_cities$city)
ggplot(df_top, aes(x = city, y = rent_mean)) +
geom_boxplot(fill = "orange") +
coord_flip() +
labs(title = "Rent Mean Distribution for Top 10 Cities", x = "City", y = "Rent Mean") +
theme_minimal()
ggplot(df_top, aes(x = debt, fill = city)) +
geom_density(alpha = 0.5) +
labs(title = "Debt Distribution in Top 10 Cities", x = "Debt", y = "Density") +
theme_minimal()
variability <- function(x) {
x <- x[!is.na(x)]   # remove missing values
range_val <- range(x)
data.frame(
Range_Min = range_val[1],
Range_Max = range_val[2],
Range = diff(range_val),
Variance = var(x),
Std_Dev = sd(x)
)
}
variability(df2$rent_mean)
variability(df2$family_income_mean)
central_tendency <- function(x) {
x <- x[!is.na(x)]   # remove missing values
# Mode function for numeric vectors
mode_val <- as.numeric(names(sort(table(x), decreasing = TRUE))[1])
data.frame(
Mean = mean(x),
Median = median(x),
Mode = mode_val
)
}
# Define events
high_rent <- df2$rent_mean > 2000
high_income <- df2$hi_mean > 100000
# Conditional probability P(high_rent | high_income)
p_high_rent_given_income <- sum(high_rent & high_income, na.rm = TRUE) / sum(high_income, na.rm = TRUE)
p_high_rent_given_income
# Thresholds
rent_med   <- median(df2$rent_mean, na.rm = TRUE)
income_med <- median(df2$hi_mean, na.rm = TRUE)
# Events
A <- df$hi_mean > income_med   # High income
B <- df$rent_mean > rent_med   # High rent
# Remove rows with missing values in A or B
valid <- complete.cases(A, B)
# Using same A (high income) and B (high rent)
pA  <- mean(A[valid])
pB  <- mean(B[valid])
pB_given_A <- mean(A[valid] & B[valid]) / pA
# Bayes: P(A|B) = P(B|A) * P(A) / P(B)
P_A_given_B_bayes <- pB_given_A * pA / pB
P_A_given_B_bayes
# Mean and SD
mu <- mean(df2$rent_mean, na.rm = TRUE)
sigma <- sd(df2$rent_mean, na.rm = TRUE)
# Probability that rent_mean < 2000
pnorm(2000, mean = mu, sd = sigma)
# Generate 1000 random samples
rent_sim <- rnorm(1000, mean = mu, sd = sigma)
# Plot
library(ggplot2)
ggplot(data.frame(rent_sim), aes(x = rent_sim)) +
geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
stat_function(fun = dnorm, args = list(mean = mu, sd = sigma), color = "red", size = 1) +
labs(title = "Normal Distribution Approximation of Rent Mean", x = "Rent Mean", y = "Density")
# Suppose 100 people in a city, probability of hs_degree = 0.85
n <- 100
p <- 0.85
# Probability exactly 90 have hs_degree
dbinom(90, size = n, prob = p)
# Probability at least 90
1 - pbinom(89, size = n, prob = p)
# Simulate 1000 cities
hs_sim <- rbinom(1000, size = n, prob = p)
hist(hs_sim, main="Binomial Distribution of hs_degree in 100 people", xlab="Number of People with HS Degree")
# Suppose on average 5 cities per state have rent_mean > 2000
lambda <- 5
# Probability exactly 7 cities
dpois(7, lambda)
# Simulate 15 states
cities_sim <- rpois(15, lambda)
hist(cities_sim, main="Poisson Distribution of High-Rent Cities", xlab="Number of Cities")
# Create categorical version of hs_degree
df2$hs_high <- ifelse(df2$hs_degree > 0.9, "High", "Low")
# Contingency table
tbl <- table(df2$hs_high, df2$state)
# Chi-square test
chi_result <- chisq.test(tbl)
chi_result
# Example: hs_degree vs type of place
tbl2 <- table(df2$hs_high, df2$type)
chisq.test(tbl2)
df2
```{r}
df2
# Linear Regression: rent_mean ~ hi_mean
model <- lm(rent_mean ~ hi_mean, data = df2)
# Summary of the regression model
summary(model)
library(ggplot2)
ggplot(df2, aes(x = hi_mean, y = rent_mean)) +
geom_point(alpha = 0.5, color = "blue") +
geom_smooth(method = "lm", se = TRUE, color = "red") +
labs(title = "Linear Regression: Rent Mean vs Household Income",
x = "Household Income (hi_mean)",
y = "Rent Mean") +
theme_minimal()
df <- read.csv("real_estate_db.csv")
head(df, 10)
columns <- c(
"UID","STATEID","BLOCKID","state","state_ab","county","city","place","type","primary",
"zip_code","area_code","lat","lng","ALand","AWater","pop","male_pop","female_pop",
"second_mortgage","home_equity","home_equity_second_mortgage","debt",
"second_mortgage_cdf","home_equity_cdf","debt_cdf",
"hs_degree","hs_degree_male","hs_degree_female",
"hc_mortgage_mean","hc_mortgage_median","hc_mortgage_stdev",
"hc_mortgage_sample","hc_mortgage_sample_weight",
"hc_mean","hc_median","hc_stdev","hc_samples","hc_sample_weight",
"rent_mean","rent_median","rent_stdev","rent_samples","rent_sample_weight",
"rent_gt_10","rent_gt_15","rent_gt_20","rent_gt_25","rent_gt_30",
"rent_gt_35","rent_gt_40","rent_gt_50","rent_universe_samples","rent_used_samples",
"family_income_mean","family_income_median","family_income_stdev","family_income_families",
"hi_mean","hi_median","hi_stdev","hi_samples","hi_sample_weight"
)
col_mapping <- c(
"family_mean" = "family_income_mean",
"family_median" = "family_income_median",
"family_stdev" = "family_income_stdev",
"family_samples" = "family_income_families",
"universe_samples" = "rent_universe_samples",
"used_samples" = "rent_used_samples",
"hc_mortgage_samples" = "hc_mortgage_sample",
"hc_mortgage_sample_weight" = "hc_mortgage_sample_weight"
)
names(df) <- ifelse(names(df) %in% names(col_mapping), col_mapping[names(df)], names(df))
df2 <- df[, intersect(names(df), columns)]
dim(df2)
object.size(df2)
str(df2)
df2 <- subset(df2, select = -c(BLOCKID, UID))
cat_cols <- c("state", "state_ab", "city", "place", "type", "primary")
df2[cat_cols] <- lapply(df2[cat_cols], as.factor)
library(stringr)
df2$city    <- str_to_title(df2$city)
df2$place   <- str_to_title(df2$place)
df2$type    <- str_to_title(df2$type)
df2$primary <- tolower(df2$primary)
colSums(is.na(df2))
num_cols <- sapply(df2, is.numeric)
df2[num_cols] <- lapply(df2[num_cols], function(x) {
x[is.na(x)] <- median(x, na.rm = TRUE)
return(x)
})
num_cols <- sapply(df2, is.numeric)
df2[num_cols] <- lapply(df2[num_cols], function(x) {
x[is.na(x)] <- median(x, na.rm = TRUE)
return(x)
})
# Function to compute mode (most frequent value)
get_mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
cat_cols <- c("state", "state_ab", "city", "place", "type", "primary")
df2[cat_cols] <- lapply(df2[cat_cols], function(x) {
mode_val <- get_mode(x[!is.na(x)])      # compute mode excluding NA
x[is.na(x)] <- mode_val                 # replace NA with mode
return(x)
})
cat_cols <- c("state", "state_ab", "city", "place", "type", "primary")
df2[cat_cols] <- lapply(df2[cat_cols], function(x) {
mode_val <- get_mode(x[!is.na(x)])      # compute mode excluding NA
x[is.na(x)] <- mode_val                 # replace NA with mode
return(x)
})
colSums(is.na(df2))
# Remove Duplicate Rows
df2 <- unique(df2)
summary(model)
df2
# Linear Regression: rent_mean ~ hi_mean
model <- lm(rent_mean ~ hi_mean, data = df2)
# Summary of the regression model
summary(model)
library(ggplot2)
ggplot(df2, aes(x = hi_mean, y = rent_mean)) +
geom_point(alpha = 0.5, color = "blue") +
geom_smooth(method = "lm", se = TRUE, color = "red") +
labs(title = "Linear Regression: Rent Mean vs Household Income",
x = "Household Income (hi_mean)",
y = "Rent Mean") +
theme_minimal()
summary(model)
# Confidence intervals for coefficients
confint(model, level = 0.95)
# Display full summary
summary(model)
# Extract specific coefficients
coefficients(model)
# Confidence intervals for coefficients
confint(model, level = 0.95)
# Extract key metrics
model_metrics <- data.frame(
Metric = c("R-squared", "Adjusted R-squared", "F-statistic",
"p-value", "Residual Std Error", "Sample Size"),
Value = c(
round(summary(model)$r.squared, 4),
round(summary(model)$adj.r.squared, 4),
round(summary(model)$fstatistic[1], 2),
format(pf(summary(model)$fstatistic[1],
summary(model)$fstatistic[2],
summary(model)$fstatistic[3],
lower.tail = FALSE), scientific = TRUE),
round(summary(model)$sigma, 2),
nobs(model)
)
)
# Display table
print(model_metrics)
# For better formatting (optional)
library(knitr)
kable(model_metrics, caption = "Model Performance Metrics")
# Modified metrics table WITHOUT p-value
model_metrics <- data.frame(
Metric = c("R-squared", "Adjusted R-squared", "F-statistic",
"Residual Std Error", "Sample Size"),
Value = c(
round(summary(model)$r.squared, 4),
round(summary(model)$adj.r.squared, 4),
round(summary(model)$fstatistic[1], 2),
round(summary(model)$sigma, 2),
nobs(model)
)
)
# Extract key metrics
model_metrics <- data.frame(
Metric = c("R-squared", "Adjusted R-squared", "F-statistic",
"p-value", "Residual Std Error", "Sample Size"),
Value = c(
round(summary(model)$r.squared, 4),
round(summary(model)$adj.r.squared, 4),
round(summary(model)$fstatistic[1], 2),
format(pf(summary(model)$fstatistic[1],
summary(model)$fstatistic[2],
summary(model)$fstatistic[3],
lower.tail = FALSE), scientific = TRUE),
round(summary(model)$sigma, 2),
nobs(model)
)
)
# Display table
print(model_metrics)
# For better formatting (optional)
library(knitr)
kable(model_metrics, caption = "Model Performance Metrics")
